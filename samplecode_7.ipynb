{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "865118d4-beae-4123-85cf-2dd95b7e78e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to ./nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to ./nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     ./nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package wordnet to ./nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to ./nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowercased Text:\n",
      " it is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.\n",
      "Punctuation characters:\n",
      " !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "\n",
      "Text without punctuation:\n",
      " it is a truth universally acknowledged that a single man in possession of a good fortune must be in want of a wife\n",
      "\n",
      "Word Tokens:\n",
      " ['it', 'is', 'a', 'truth', 'universally', 'acknowledged', 'that', 'a', 'single', 'man', 'in', 'possession', 'of', 'a', 'good', 'fortune', 'must', 'be', 'in', 'want', 'of', 'a', 'wife']\n",
      "\n",
      "Sentence Tokens:\n",
      " ['it is a truth universally acknowledged that a single man in possession of a good fortune must be in want of a wife']\n",
      "\n",
      "Filtered Words (no stopwords):\n",
      " ['truth', 'universally', 'acknowledged', 'single', 'man', 'possession', 'good', 'fortune', 'must', 'want', 'wife']\n",
      "\n",
      "Stemmed Words:\n",
      " ['truth', 'univers', 'acknowledg', 'singl', 'man', 'possess', 'good', 'fortun', 'must', 'want', 'wife']\n",
      "\n",
      "POS Tags:\n",
      " [('truth', 'NN'), ('universally', 'RB'), ('acknowledged', 'VBD'), ('single', 'JJ'), ('man', 'NN'), ('possession', 'NN'), ('good', 'JJ'), ('fortune', 'NN'), ('must', 'MD'), ('want', 'VB'), ('wife', 'NN')]\n",
      "\n",
      "Lemmatized Words:\n",
      " ['truth', 'universally', 'acknowledged', 'single', 'man', 'possession', 'good', 'fortune', 'must', 'want', 'wife']\n",
      "\n",
      "TF-IDF Terms:\n",
      " ['acknowledged' 'fortune' 'good' 'man' 'possession' 'single' 'truth'\n",
      " 'universally' 'want' 'wife']\n",
      "\n",
      "TF-IDF Values:\n",
      " [[0.31622777 0.31622777 0.31622777 0.31622777 0.31622777 0.31622777\n",
      "  0.31622777 0.31622777 0.31622777 0.31622777]]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk import word_tokenize, sent_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Download required resources\n",
    "nltk.download('punkt', download_dir='./nltk_data')\n",
    "nltk.download('stopwords', download_dir='./nltk_data')\n",
    "nltk.download('averaged_perceptron_tagger', download_dir='./nltk_data')\n",
    "nltk.download('wordnet', download_dir='./nltk_data')\n",
    "nltk.download('omw-1.4', download_dir='./nltk_data')  # for lemmatizer\n",
    "\n",
    "# Input text\n",
    "text = \"It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.\"\n",
    "text = text.lower()\n",
    "print(\"Lowercased Text:\\n\", text)\n",
    "\n",
    "# Remove punctuation\n",
    "print(\"Punctuation characters:\\n\", string.punctuation)\n",
    "text_p = \"\".join([char for char in text if char not in string.punctuation])\n",
    "print(\"\\nText without punctuation:\\n\", text_p)\n",
    "\n",
    "# Tokenization\n",
    "words = word_tokenize(text_p)\n",
    "sentences = sent_tokenize(text_p)\n",
    "print(\"\\nWord Tokens:\\n\", words)\n",
    "print(\"\\nSentence Tokens:\\n\", sentences)\n",
    "\n",
    "# Stopwords removal\n",
    "stop_words = stopwords.words('english')\n",
    "filtered_words = [word for word in words if word not in stop_words]\n",
    "print(\"\\nFiltered Words (no stopwords):\\n\", filtered_words)\n",
    "\n",
    "# Stemming\n",
    "porter = PorterStemmer()\n",
    "stemmed = [porter.stem(word) for word in filtered_words]\n",
    "print(\"\\nStemmed Words:\\n\", stemmed)\n",
    "\n",
    "# POS tagging\n",
    "pos = pos_tag(filtered_words)\n",
    "print(\"\\nPOS Tags:\\n\", pos)\n",
    "\n",
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
    "print(\"\\nLemmatized Words:\\n\", lemmatized)\n",
    "\n",
    "# TF-IDF Calculation\n",
    "corpus = [text]\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "terms = tfidf_vectorizer.get_feature_names_out()\n",
    "print(\"\\nTF-IDF Terms:\\n\", terms)\n",
    "\n",
    "tfidf_values = tfidf_matrix.toarray()\n",
    "print(\"\\nTF-IDF Values:\\n\", tfidf_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "756b863c-1df2-4e76-9690-39d6480e1086",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Rahul\n",
      "[nltk_data]     Wanjare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Rahul\n",
      "[nltk_data]     Wanjare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Rahul Wanjare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Rahul\n",
      "[nltk_data]     Wanjare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Rahul\n",
      "[nltk_data]     Wanjare\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      " it is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.\n",
      "\n",
      "Filtered Words:\n",
      " ['truth', 'universally', 'acknowledged', 'single', 'man', 'possession', 'good', 'fortune', 'must', 'want', 'wife']\n",
      "\n",
      "Stemmed Words:\n",
      " ['truth', 'univers', 'acknowledg', 'singl', 'man', 'possess', 'good', 'fortun', 'must', 'want', 'wife']\n",
      "\n",
      "POS Tags:\n",
      " [('truth', 'NN'), ('universally', 'RB'), ('acknowledged', 'VBD'), ('single', 'JJ'), ('man', 'NN'), ('possession', 'NN'), ('good', 'JJ'), ('fortune', 'NN'), ('must', 'MD'), ('want', 'VB'), ('wife', 'NN')]\n",
      "\n",
      "Lemmatized Words:\n",
      " ['truth', 'universally', 'acknowledge', 'single', 'man', 'possession', 'good', 'fortune', 'must', 'want', 'wife']\n",
      "\n",
      "TF-IDF Terms:\n",
      " ['acknowledged' 'fortune' 'good' 'man' 'possession' 'single' 'truth'\n",
      " 'universally' 'want' 'wife']\n",
      "\n",
      "TF-IDF Values:\n",
      " [[0.31622777 0.31622777 0.31622777 0.31622777 0.31622777 0.31622777\n",
      "  0.31622777 0.31622777 0.31622777 0.31622777]]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk import word_tokenize, sent_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Download necessary resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Sample text\n",
    "text = \"It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.\"\n",
    "text = text.lower()\n",
    "\n",
    "# Remove punctuation\n",
    "text_p = \"\".join([char for char in text if char not in string.punctuation])\n",
    "\n",
    "# Tokenize\n",
    "words = word_tokenize(text_p)\n",
    "sentences = sent_tokenize(text_p)\n",
    "\n",
    "# Remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_words = [word for word in words if word not in stop_words]\n",
    "\n",
    "# Stemming\n",
    "stemmer = PorterStemmer()\n",
    "stemmed = [stemmer.stem(word) for word in filtered_words]\n",
    "\n",
    "# POS tagging\n",
    "pos_tags = pos_tag(filtered_words)\n",
    "\n",
    "# Function to map POS tags to WordNet format\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN  # default to noun\n",
    "\n",
    "# Lemmatization with POS\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized = [lemmatizer.lemmatize(word, get_wordnet_pos(tag)) for word, tag in pos_tags]\n",
    "\n",
    "# TF-IDF\n",
    "corpus = [text]\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Output\n",
    "print(\"Original Text:\\n\", text)\n",
    "print(\"\\nFiltered Words:\\n\", filtered_words)\n",
    "print(\"\\nStemmed Words:\\n\", stemmed)\n",
    "print(\"\\nPOS Tags:\\n\", pos_tags)\n",
    "print(\"\\nLemmatized Words:\\n\", lemmatized)\n",
    "print(\"\\nTF-IDF Terms:\\n\", terms)\n",
    "print(\"\\nTF-IDF Values:\\n\", X.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004e5d47-556d-441b-b344-995d8f834731",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
